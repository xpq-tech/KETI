{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FT_Precision_llama31 = np.array([0.712, 0.843, 0.856, 0.823, 0.808, 0.849, 0.863])\n",
    "GRACE_Precision_llama31 = np.array([0.778,0.833,0.827,0.808,0.772,0.781,0.770])\n",
    "UNKE_Precision_llama31 = np.array([0.783,0.846,0.859,0.810,0.797,0.805,0.831])\n",
    "\n",
    "FT_Precision_llama2 = np.array([0.790,0.842,0.797,0.787,0.772,0.842,0.815])\n",
    "GRACE_Precision_llama2 = np.array([0.775,0.815,0.808,0.675,0.797,0.805,0.813])\n",
    "UNKE_Precision_llama2 = np.array([0.741,0.819,0.789,0.706,0.798,0.786,0.793])\n",
    "\n",
    "FT_F1_llama31 = np.array([0.711,0.842,0.837,0.821,0.771,0.847,0.861])\n",
    "GRACE_F1_llama31 = np.array([0.778,0.834,0.823,0.796,0.763,0.770,0.762])\n",
    "UNKE_F1_llama31 = np.array([0.782,0.847,0.854,0.801,0.796,0.782,0.818])\n",
    "\n",
    "FT_F1_llama2 = np.array([0.789,0.840,0.783,0.764,0.747,0.807,0.818])\n",
    "GRACE_F1_llama2 = np.array([0.777,0.816,0.804,0.614,0.781,0.757,0.801])\n",
    "UNKE_F1_llama2 = np.array([0.744,0.819,0.754,0.694,0.778,0.763,0.797])\n",
    "\n",
    "FT_Recall_llama31 = np.array([0.714,0.843,0.837,0.828,0.756,0.847,0.861])\n",
    "GRACE_Recall_llama31 = np.array([0.778,0.837,0.834,0.814,0.767,0.764,0.765])\n",
    "UNKE_Recall_llama31 = np.array([0.783,0.850,0.855,0.819,0.802,0.772,0.818])\n",
    "\n",
    "FT_Recall_llama2 = np.array([0.789,0.841,0.795,0.763,0.735,0.795,0.825])\n",
    "GRACE_Recall_llama2 = np.array([0.780,0.820,0.801,0.636,0.781,0.755,0.813])\n",
    "UNKE_Recall_llama2 = np.array([0.750,0.820,0.746,0.710,0.769,0.773,0.798])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mode can be mean, max, min, and index[0-6], 0-6 corresponding to 'LDA', \"LogR\", \"Linear\", \"MLP\",\"BERT-text only\", \"BERT+SFLP\", \"BERT+LSTM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"index6\" ##\n",
    "metrics = ['F1', 'Recall', 'Precision']\n",
    "method = ['LDA', \"LogR\", \"Linear\", \"MLP\",\"BERT-text only\", \"BERT+SFLP\", \"BERT+LSTM\"]\n",
    "\n",
    "if mode == \"mean\":\n",
    "    data = {\n",
    "        'Reliability': [0.993, 0.983, 0.393,0.996,0.999,0.021],\n",
    "        'Precision': [FT_Precision_llama31.mean(), GRACE_Precision_llama31.mean(),UNKE_Precision_llama31.mean(),FT_Precision_llama2.mean(), GRACE_Precision_llama2.mean(),UNKE_Precision_llama2.mean()],\n",
    "        'F1': [FT_F1_llama31.mean(), GRACE_F1_llama31.mean(), UNKE_F1_llama31.mean(), FT_F1_llama2.mean(), GRACE_F1_llama2.mean(),UNKE_F1_llama2.mean()],\n",
    "        'Recall': [FT_Recall_llama31.mean(), GRACE_Recall_llama31.mean(), UNKE_Recall_llama31.mean(), FT_Recall_llama2.mean(), GRACE_Recall_llama2.mean(),UNKE_Recall_llama2.mean()],\n",
    "    }\n",
    "elif mode == \"max\":\n",
    "       data = {\n",
    "        'Reliability': [0.993, 0.983, 0.393,0.996,0.999,0.021],\n",
    "        'Precision': [FT_Precision_llama31.max(), GRACE_Precision_llama31.max(),UNKE_Precision_llama31.max(),FT_Precision_llama2.max(), GRACE_Precision_llama2.max(),UNKE_Precision_llama2.max()],\n",
    "        'F1': [FT_F1_llama31.max(), GRACE_F1_llama31.max(), UNKE_F1_llama31.max(), FT_F1_llama2.max(), GRACE_F1_llama2.max(),UNKE_F1_llama2.max()],\n",
    "        'Recall': [FT_Recall_llama31.max(), GRACE_Recall_llama31.max(), UNKE_Recall_llama31.max(), FT_Recall_llama2.max(), GRACE_Recall_llama2.max(),UNKE_Recall_llama2.max()],\n",
    "       }\n",
    "elif mode == \"min\":\n",
    "     data = {\n",
    "        'Reliability': [0.993, 0.983, 0.393,0.996,0.999,0.021],\n",
    "        'Precision': [FT_Precision_llama31.min(), GRACE_Precision_llama31.min(),UNKE_Precision_llama31.min(),FT_Precision_llama2.min(), GRACE_Precision_llama2.min(),UNKE_Precision_llama2.min()],\n",
    "        'F1': [FT_F1_llama31.min(), GRACE_F1_llama31.min(), UNKE_F1_llama31.min(), FT_F1_llama2.min(), GRACE_F1_llama2.min(),UNKE_F1_llama2.min()],\n",
    "        'Recall': [FT_Recall_llama31.min(), GRACE_Recall_llama31.min(), UNKE_Recall_llama31.min(), FT_Recall_llama2.min(), GRACE_Recall_llama2.min(),UNKE_Recall_llama2.min()],\n",
    "        }\n",
    "elif 'index' in mode:\n",
    "     index = int(mode[-1])\n",
    "     data = {\n",
    "        'Reliability': [0.993, 0.983, 0.393,0.996,0.999,0.021],\n",
    "        'Precision': [FT_Precision_llama31[index], GRACE_Precision_llama31[index],UNKE_Precision_llama31[index],FT_Precision_llama2[index], GRACE_Precision_llama2[index],UNKE_Precision_llama2[index]],\n",
    "        'F1': [FT_F1_llama31[index], GRACE_F1_llama31[index], UNKE_F1_llama31[index], FT_F1_llama2[index], GRACE_F1_llama2[index],UNKE_F1_llama2[index]],\n",
    "        'Recall': [FT_Recall_llama31[index], GRACE_Recall_llama31[index], UNKE_Recall_llama31[index], FT_Recall_llama2[index], GRACE_Recall_llama2[index],UNKE_Recall_llama2[index]],\n",
    "       }\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "correlations = []\n",
    "colors = [[\"#82B0D2\", \"#FA7F6F\"], [\"#8ECFC9\",\"#FFBE7A\"], [\"#BEB8DC\",\"#E7DAD2\"]]\n",
    "custom_palette = sns.color_palette(['#82B0D2', '#FA7F6F', '#8ECFC9']) \n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    correlations.append(df['Reliability'].corr(df[metric]))\n",
    "    sns.regplot(x='Reliability', y=metric, data=df,ci=68, label=metric)\n",
    "    # sns.scatterplot(x='Reliability', y=metric, hue=[metric]*6, data=df, palette=sns.color_palette([colors[i][1]]))\n",
    "plt.title(f'Correlations: Precision: {correlations[2]:.2f}, Recall: {correlations[1]:.2f}, F1: {correlations[0]:.2f}')\n",
    "plt.xlabel('Reliability')\n",
    "if 'index' in mode:\n",
    "    mode = method[index]\n",
    "\n",
    "plt.ylabel(f'Metrics-{mode}')\n",
    "plt.legend(loc='best') \n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"./figs/Correlations_{mode}.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Domian "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results of Cross Domian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Llama3.1\n",
    "FT_M_LogR = [0.843,0.843,0.842]\n",
    "FT_M_2_GRACE_LogR = [0.478,0.396,0.342]\n",
    "FT_M_2_UnKE_LogR = [0.706,0.499,0.442]\n",
    "\n",
    "GRACE_LogR = [0.833,0.837,0.834]\n",
    "GRACE_2_FT_M_LogR = [0.564,0.409,0.362]\n",
    "GRACE_2_UnKE_LogR = [0.698,0.582,0.597]\n",
    "\n",
    "UnKE_LogR = [0.846,0.850,0.847]\n",
    "UnKE_2_FT_M_LogR = [0.624,0.531,0.528]\n",
    "UnKE_2_GRACE_LogR = [0.677,0.501,0.476]\n",
    "\n",
    "FT_M = [0.863, 0.861, 0.861]\n",
    "FT_M_2_GRACE = [0.132, 0.178, 0.075]\n",
    "FT_M_2_UnKE = [0.729, 0.553, 0.592]\n",
    "\n",
    "GRACE = [0.770,0.765,0.762]\n",
    "GRACE_2_FT_M = [0.772,0.773,0.764]\n",
    "GRACE_2_UnKE = [0.767,0.767,0.759]\n",
    "\n",
    "UnKE = [0.831,0.818,0.818]\n",
    "UnKE_2_FT_M = [0.813,0.805,0.803]\n",
    "UnKE_2_GRACE = [0.708,0.661,0.665]\n",
    "\n",
    "\n",
    "# Llama2-13B\n",
    "FT_M_LogR_llama2 = [0.842,0.841,0.840]\n",
    "FT_M_2_GRACE_LogR_llama2 = [0.794, 0.234, 0.165]\n",
    "FT_M_2_UnKE_LogR_llama2 = [0.574 ,0.265, 0.202]\n",
    "\n",
    "GRACE_LogR_llama2 = [0.815,0.820,0.816]\n",
    "GRACE_2_FT_M_LogR_llama2 = [0.768, 0.724, 0.719]\n",
    "GRACE_2_UnKE_LogR_llama2 = [0.799,0.805, 0.801]\n",
    "\n",
    "UnKE_LogR_llama2 = [0.819,0.820,0.819]\n",
    "UnKE_2_FT_M_LogR_llama2 = [0.775, 0.773, 0.772]\n",
    "UnKE_2_GRACE_LogR_llama2 = [0.819, 0.827, 0.822]\n",
    "\n",
    "\n",
    "FT_M_llama2 = [0.815,0.825,0.818]\n",
    "FT_M_2_GRACE_llama2 = [0.527,0.524, 0.493]\n",
    "FT_M_2_UnKE_llama2 = [0.527, 0.527, 0.494]\n",
    "\n",
    "GRACE_llama2 = [0.813,0.813,0.801]\n",
    "GRACE_2_FT_M_llama2 = [0.814, 0.818, 0.803]\n",
    "GRACE_2_UnKE_llama2 = [0.808 ,0.805 ,0.794]\n",
    "\n",
    "UnKE_llama2 = [0.798,0.798,0.797]\n",
    "UnKE_2_FT_M_llama2 = [0.768, 0.767, 0.766]\n",
    "UnKE_2_GRACE_llama2 = [0.799, 0.798, 0.797]\n",
    "\n",
    "# 定义x轴标签\n",
    "metrics = ['Precision', 'Recall', 'F1']\n",
    "x = np.arange(len(metrics))  # x轴的位置\n",
    "\n",
    "# 设置柱状图的宽度\n",
    "width = 0.25\n",
    "\n",
    "# 创建图形\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 6), sharey=True)\n",
    "\n",
    "#Llama3.1\n",
    "# 绘制FT_M、FT_M_A和FT_M_B的重叠柱状图，先绘制底层，再绘制上层\n",
    "axs[0,0].bar(x - width, FT_M_LogR, width, label='FT-M', color='#63b2ee',  zorder=1)\n",
    "axs[0,0].bar(x - width, FT_M_2_GRACE_LogR, width, label=r'FT-M$\\rightarrow$GRACE', color='#76da91', zorder=3)\n",
    "axs[0,0].bar(x - width, FT_M_2_UnKE_LogR, width, label=r'FT-M$\\rightarrow$UnKE', color='#f8cb7f',  zorder=2)\n",
    "\n",
    "# 绘制GRACE、GRACE_A和GRACE_B的重叠柱状图\n",
    "axs[0,0].bar(x, GRACE_LogR, width, label='GRACE', color='#f89588', zorder=1)\n",
    "axs[0,0].bar(x, GRACE_2_FT_M_LogR, width, label=r'GRACE$\\rightarrow$FT-M', color='#7cd6cf',  zorder=3)\n",
    "axs[0,0].bar(x, GRACE_2_UnKE_LogR, width, label=r'GRACE$\\rightarrow$UnKE', color='#9192ab', zorder=2)\n",
    "\n",
    "# 绘制UnKE、UnKE_A和UnKE_B的重叠柱状图\n",
    "axs[0,0].bar(x + width, UnKE_LogR, width, label='UnKE', color='#7898e1',  zorder=1)\n",
    "axs[0,0].bar(x + width, UnKE_2_FT_M_LogR, width, label=r'UnKE$\\rightarrow$FT-M', color='#efa666',  zorder=2)\n",
    "axs[0,0].bar(x + width, UnKE_2_GRACE_LogR, width, label=r'UnKE$\\rightarrow$GRACE', color='#9987ce', zorder=3)\n",
    "\n",
    "# 设置x轴标签和标题\n",
    "axs[0,0].set_xticks(x)\n",
    "axs[0,0].set_xticklabels(metrics)\n",
    "axs[0,0].set_title('Cross domain Changes in LogR (Llama3.1-8B)')\n",
    "\n",
    "# 绘制FT_M、FT_M_A和FT_M_B的重叠柱状图，先绘制底层，再绘制上层\n",
    "axs[0,1].bar(x - width, FT_M, width, label='FT-M', color='#63b2ee',  zorder=1)\n",
    "axs[0,1].bar(x - width, FT_M_2_GRACE, width, label=r'FT-M$\\rightarrow$GRACE', color='#76da91', zorder=3)\n",
    "axs[0,1].bar(x - width, FT_M_2_UnKE, width, label=r'FT-M$\\rightarrow$UnKE', color='#f8cb7f',  zorder=2)\n",
    "\n",
    "# 绘制GRACE、GRACE_A和GRACE_B的重叠柱状图\n",
    "axs[0,1].bar(x, GRACE, width, label='GRACE', color='#f89588', zorder=2)\n",
    "axs[0,1].bar(x, GRACE_2_FT_M, width, label=r'GRACE$\\rightarrow$FT-M', color='#7cd6cf',  zorder=1)\n",
    "axs[0,1].bar(x, GRACE_2_UnKE, width, label=r'GRACE$\\rightarrow$UnKE', color='#9192ab', zorder=3)\n",
    "\n",
    "# 绘制UnKE、UnKE_A和UnKE_B的重叠柱状图\n",
    "axs[0,1].bar(x + width, UnKE, width, label='UnKE', color='#7898e1',  zorder=1)\n",
    "axs[0,1].bar(x + width, UnKE_2_FT_M, width, label=r'UnKE$\\rightarrow$FT-M', color='#efa666',  zorder=2)\n",
    "axs[0,1].bar(x + width, UnKE_2_GRACE, width, label=r'UnKE$\\rightarrow$GRACE', color='#9987ce', zorder=3)\n",
    "\n",
    "# 设置x轴标签和标题\n",
    "axs[0,1].set_xticks(x)\n",
    "axs[0,1].set_xticklabels(metrics)\n",
    "axs[0,1].set_title('Cross domain Changes in BERT+LSTM (Llama3.1-8B)')\n",
    "\n",
    "#Llama2\n",
    "axs[1,0].bar(x - width, FT_M_LogR_llama2, width, label='FT-M', color='#63b2ee',  zorder=1)\n",
    "axs[1,0].bar(x - width, FT_M_2_GRACE_LogR_llama2, width, label=r'FT-M$\\rightarrow$GRACE', color='#76da91', zorder=3)\n",
    "axs[1,0].bar(x - width, FT_M_2_UnKE_LogR_llama2, width, label=r'FT-M$\\rightarrow$UnKE', color='#f8cb7f',  zorder=2)\n",
    "\n",
    "# 绘制GRACE、GRACE_A和GRACE_B的重叠柱状图\n",
    "axs[1,0].bar(x, GRACE_LogR_llama2, width, label='GRACE', color='#f89588', zorder=1)\n",
    "axs[1,0].bar(x, GRACE_2_FT_M_LogR_llama2, width, label=r'GRACE$\\rightarrow$FT-M', color='#7cd6cf',  zorder=3)\n",
    "axs[1,0].bar(x, GRACE_2_UnKE_LogR_llama2, width, label=r'GRACE$\\rightarrow$UnKE', color='#9192ab', zorder=2)\n",
    "\n",
    "# 绘制UnKE、UnKE_A和UnKE_B的重叠柱状图\n",
    "axs[1,0].bar(x + width, UnKE_LogR_llama2, width, label='UnKE', color='#7898e1',  zorder=1)\n",
    "axs[1,0].bar(x + width, UnKE_2_FT_M_LogR_llama2, width, label=r'UnKE$\\rightarrow$FT-M', color='#efa666',  zorder=3)\n",
    "axs[1,0].bar(x + width, UnKE_2_GRACE_LogR_llama2, width, label=r'UnKE$\\rightarrow$GRACE', color='#9987ce', zorder=2)\n",
    "\n",
    "# 设置x轴标签和标题\n",
    "axs[1,0].set_xticks(x)\n",
    "axs[1,0].set_xticklabels(metrics)\n",
    "axs[1,0].set_title('Cross domain Changes in LogR (Llama2-13B)')\n",
    "\n",
    "# 绘制FT_M、FT_M_A和FT_M_B的重叠柱状图，先绘制底层，再绘制上层\n",
    "axs[1,1].bar(x - width, FT_M_llama2, width, label='FT-M', color='#63b2ee',  zorder=1)\n",
    "axs[1,1].bar(x - width, FT_M_2_GRACE_llama2, width, label=r'FT-M$\\rightarrow$GRACE', color='#76da91', zorder=3)\n",
    "axs[1,1].bar(x - width, FT_M_2_UnKE_llama2, width, label=r'FT-M$\\rightarrow$UnKE', color='#f8cb7f',  zorder=2)\n",
    "\n",
    "# 绘制GRACE、GRACE_A和GRACE_B的重叠柱状图\n",
    "axs[1,1].bar(x, GRACE_llama2, width, label='GRACE', color='#f89588', zorder=2)\n",
    "axs[1,1].bar(x, GRACE_2_FT_M_llama2, width, label=r'GRACE$\\rightarrow$FT-M', color='#7cd6cf',  zorder=1)\n",
    "axs[1,1].bar(x, GRACE_2_UnKE_llama2, width, label=r'GRACE$\\rightarrow$UnKE', color='#9192ab', zorder=3)\n",
    "\n",
    "# 绘制UnKE、UnKE_A和UnKE_B的重叠柱状图\n",
    "axs[1,1].bar(x + width, UnKE_llama2, width, label='UnKE', color='#7898e1',  zorder=1)\n",
    "axs[1,1].bar(x + width, UnKE_2_FT_M_llama2, width, label=r'UnKE$\\rightarrow$FT-M', color='#efa666',  zorder=3)\n",
    "axs[1,1].bar(x + width, UnKE_2_GRACE_llama2, width, label=r'UnKE$\\rightarrow$GRACE', color='#9987ce', zorder=2)\n",
    "\n",
    "# 设置x轴标签和标题\n",
    "axs[1,1].set_xticks(x)\n",
    "axs[1,1].set_xticklabels(metrics)\n",
    "axs[1,1].set_title('Cross domain Changes in BERT+LSTM (Llama2-13B)')\n",
    "\n",
    "handles1, labels1 = axs[0,0].get_legend_handles_labels()\n",
    "fig.legend(handles1, labels1, bbox_to_anchor=(0.5, 0.01), loc='upper center', ncol=3)\n",
    "\n",
    "# 显示图形\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./figs/cross_domain.pdf\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the number of instances where Llama 3.1's performance exceeds 60% in cross-domain experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# 数据\n",
    "FT_M_LogR = [0.843,0.843,0.842]\n",
    "FT_M_2_GRACE_LogR = [0.478,0.396,0.342]\n",
    "FT_M_2_UnKE_LogR = [0.706,0.499,0.442]\n",
    "\n",
    "GRACE_LogR = [0.833,0.837,0.834]\n",
    "GRACE_2_FT_M_LogR = [0.564,0.409,0.362]\n",
    "GRACE_2_UnKE_LogR = [0.698,0.582,0.597]\n",
    "\n",
    "UnKE_LogR = [0.846,0.850,0.847]\n",
    "UnKE_2_FT_M_LogR = [0.624,0.531,0.528]\n",
    "UnKE_2_GRACE_LogR = [0.677,0.501,0.476]\n",
    "\n",
    "FT_M = [0.863, 0.861, 0.861]\n",
    "FT_M_2_GRACE = [0.132, 0.178, 0.075]\n",
    "FT_M_2_UnKE = [0.729, 0.553, 0.592]\n",
    "\n",
    "GRACE = [0.770,0.765,0.762]\n",
    "GRACE_2_FT_M = [0.772,0.773,0.764]\n",
    "GRACE_2_UnKE = [0.767,0.767,0.759]\n",
    "\n",
    "UnKE = [0.831,0.818,0.818]\n",
    "UnKE_2_FT_M = [0.813,0.805,0.803]\n",
    "UnKE_2_GRACE = [0.708,0.661,0.665]\n",
    "\n",
    "# 计算达到60%的阈值\n",
    "def ca(orignal, A, B):\n",
    "    thresholds = [0.6 * value for value in orignal]\n",
    "\n",
    "    # 计算FT_M_2_GRACE_LogR中达到60%阈值的元素数量\n",
    "    count_A = sum(1 for i in range(len(A)) if A[i] >= thresholds[i])\n",
    "\n",
    "    # 计算FT_M_2_UnKE_LogR中达到60%阈值的元素数量\n",
    "    count_B = sum(1 for i in range(len(B)) if B[i] >= thresholds[i])\n",
    "\n",
    "    return count_A, count_B\n",
    "\n",
    "all_counts = 0\n",
    "\n",
    "a, b = ca(FT_M_LogR,FT_M_2_GRACE_LogR, FT_M_2_UnKE_LogR)\n",
    "all_counts = a + b\n",
    "a, b = ca(GRACE_LogR,GRACE_2_FT_M_LogR, GRACE_2_UnKE_LogR)\n",
    "all_counts+=(a+b)\n",
    "a, b =ca(UnKE_LogR,UnKE_2_FT_M_LogR, UnKE_2_GRACE_LogR)\n",
    "all_counts+=(a+b)\n",
    "a,b = ca(FT_M,FT_M_2_GRACE, FT_M_2_UnKE)\n",
    "all_counts+=(a+b)\n",
    "a,b=ca(GRACE,GRACE_2_FT_M, GRACE_2_UnKE)\n",
    "all_counts+=(a+b)\n",
    "a,b=ca(UnKE,UnKE_2_FT_M, UnKE_2_GRACE)\n",
    "all_counts+=(a+b)\n",
    "print(all_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the number of instances where Llama 2's performance exceeds 60% in cross-domain experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "FT_M_LogR_llama2 = [0.842,0.841,0.840]\n",
    "FT_M_2_GRACE_LogR_llama2 = [0.794, 0.234, 0.165]\n",
    "FT_M_2_UnKE_LogR_llama2 = [0.574 ,0.265, 0.202]\n",
    "\n",
    "GRACE_LogR_llama2 = [0.815,0.820,0.816]\n",
    "GRACE_2_FT_M_LogR_llama2 = [0.768, 0.724, 0.719]\n",
    "GRACE_2_UnKE_LogR_llama2 = [0.799,0.805, 0.801]\n",
    "\n",
    "UnKE_LogR_llama2 = [0.819,0.820,0.819]\n",
    "UnKE_2_FT_M_LogR_llama2 = [0.775, 0.773, 0.772]\n",
    "UnKE_2_GRACE_LogR_llama2 = [0.819, 0.827, 0.822]\n",
    "\n",
    "\n",
    "FT_M_llama2 = [0.815,0.825,0.818]\n",
    "FT_M_2_GRACE_llama2 = [0.527,0.524, 0.493]\n",
    "FT_M_2_UnKE_llama2 = [0.527, 0.527, 0.494]\n",
    "\n",
    "GRACE_llama2 = [0.813,0.813,0.801]\n",
    "GRACE_2_FT_M_llama2 = [0.814, 0.818, 0.803]\n",
    "GRACE_2_UnKE_llama2 = [0.808 ,0.805 ,0.794]\n",
    "\n",
    "UnKE_llama2 = [0.798,0.798,0.797]\n",
    "UnKE_2_FT_M_llama2 = [0.768, 0.767, 0.766]\n",
    "UnKE_2_GRACE_llama2 = [0.799, 0.798, 0.797]\n",
    "\n",
    "\n",
    "all_counts = 0\n",
    "\n",
    "a, b = ca(FT_M_LogR_llama2,FT_M_2_GRACE_LogR_llama2, FT_M_2_UnKE_LogR_llama2)\n",
    "all_counts = a + b\n",
    "a, b = ca(GRACE_LogR_llama2,GRACE_2_FT_M_LogR_llama2, GRACE_2_UnKE_LogR_llama2)\n",
    "all_counts+=(a+b)\n",
    "a, b =ca(UnKE_LogR_llama2,UnKE_2_FT_M_LogR_llama2, UnKE_2_GRACE_LogR_llama2)\n",
    "all_counts+=(a+b)\n",
    "a,b = ca(FT_M_llama2,FT_M_2_GRACE_llama2, FT_M_2_UnKE_llama2)\n",
    "all_counts+=(a+b)\n",
    "a,b=ca(GRACE_llama2,GRACE_2_FT_M_llama2, GRACE_2_UnKE_llama2)\n",
    "all_counts+=(a+b)\n",
    "a,b=ca(UnKE_llama2,UnKE_2_FT_M_llama2, UnKE_2_GRACE_llama2)\n",
    "all_counts+=(a+b)\n",
    "print(all_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "BERT_ft_SFLP_Llama_2_13b_chat_hf = np.array([\n",
    "    [60,  6, 16,  0,  1,  0],\n",
    "    [ 3, 63,  1,  0,  0,  0],\n",
    "    [ 3,  1, 79,  1,  8,  1],\n",
    "    [ 0,  0,  6, 24, 10,  4],\n",
    "    [ 3,  0, 11,  1, 78,  0],\n",
    "    [ 0,  1,  6,  0,  0, 47]\n",
    "])\n",
    "\n",
    "BERT_ft_SFLP_Meta_Llama_3_1_8B_Instruct = np.array([\n",
    "    [63,  4, 13,  0,  2,  1],\n",
    "    [ 1, 66,  0,  0,  0,  0],\n",
    "    [ 2,  1, 82,  1,  6,  1],\n",
    "    [ 1,  0,  1, 33,  5,  4],\n",
    "    [10,  0,  8,  4, 71,  0],\n",
    "    [ 0,  0,  1,  2,  0, 51]\n",
    "])\n",
    "\n",
    "BERT_ft_text_only_Llama_2_13b_chat_hf = np.array([\n",
    "    [58,  1, 19,  0,  3,  2],\n",
    "    [ 8, 58,  0,  1,  0,  0],\n",
    "    [15,  0, 66,  1, 11,  0],\n",
    "    [ 8,  0,  1, 22, 11,  2],\n",
    "    [13,  0,  5,  3, 71,  1],\n",
    "    [ 3,  0,  1,  3,  0, 47]\n",
    "])\n",
    "\n",
    "BERT_ft_text_only_Meta_Llama_3_1_8B_Instruct = np.array([\n",
    "    [66,  0, 11,  1,  3,  2],\n",
    "    [ 8, 59,  0,  0,  0,  0],\n",
    "    [17,  0, 63,  0, 12,  1],\n",
    "    [ 4,  0,  0, 25, 12,  3],\n",
    "    [19,  0,  4,  1, 69,  0],\n",
    "    [ 3,  0,  0,  1,  3, 47]\n",
    "])\n",
    "\n",
    "BERT_grace_SFLP_Llama_2_13b_chat_hf = np.array([\n",
    "    [54,  2, 20,  0,  0,  7],\n",
    "    [ 6, 61,  0,  0,  0,  0],\n",
    "    [ 1,  0, 81,  1,  9,  1],\n",
    "    [ 2,  0,  4, 18, 11,  9],\n",
    "    [12,  0, 11,  0, 69,  1],\n",
    "    [ 1,  0,  2,  0,  0, 51]\n",
    "])\n",
    "\n",
    "BERT_grace_SFLP_Meta_Llama_3_1_8B_Instruct = np.array([\n",
    "    [57,  2, 16,  0,  6,  2],\n",
    "    [ 4, 63,  0,  0,  0,  0],\n",
    "    [10,  1, 72,  1,  8,  1],\n",
    "    [ 2,  0,  3, 24, 10,  5],\n",
    "    [ 9,  0,  8,  3, 73,  0],\n",
    "    [ 1,  0,  2,  5,  0, 46]\n",
    "])\n",
    "\n",
    "BERT_grace_text_only_Llama_2_13b_chat_hf = np.array([\n",
    "    [63,  2, 13,  0,  5,  0],\n",
    "    [ 2, 64,  1,  0,  0,  0],\n",
    "    [20,  0, 61,  3,  9,  0],\n",
    "    [ 0,  0,  1, 36,  7,  0],\n",
    "    [10,  0,  3,  6, 74,  0],\n",
    "    [ 2,  0,  0, 14,  0, 38]\n",
    "])\n",
    "\n",
    "BERT_grace_text_only_Meta_Llama_3_1_8B_Instruct = np.array([\n",
    "    [58,  2, 11,  2,  7,  3],\n",
    "    [ 1, 65,  0,  0,  1,  0],\n",
    "    [15,  0, 57,  8, 13,  0],\n",
    "    [ 1,  0,  1, 31,  8,  3],\n",
    "    [ 5,  0,  2,  3, 83,  0],\n",
    "    [ 0,  0,  0, 15,  0, 39]\n",
    "])\n",
    "\n",
    "BERT_unke_SFLP_Llama_2_13b_chat_hf = np.array([\n",
    "    [45,  8, 17,  0, 10,  3],\n",
    "    [ 0, 67,  0,  0,  0,  0],\n",
    "    [ 8,  3, 66,  0, 12,  4],\n",
    "    [ 0,  0,  1, 22,  8, 13],\n",
    "    [ 2,  0,  3,  4, 84,  0],\n",
    "    [ 0,  0,  0,  1,  0, 53]\n",
    "])\n",
    "\n",
    "BERT_unke_SFLP_Meta_Llama_3_1_8B_Instruct = np.array([\n",
    "    [57,  1, 22,  0,  1,  2],\n",
    "    [ 2, 65,  0,  0,  0,  0],\n",
    "    [ 5,  0, 81,  0,  7,  0],\n",
    "    [ 4,  0,  4, 28,  4,  4],\n",
    "    [18,  0,  9,  5, 61,  0],\n",
    "    [ 2,  0,  7,  1,  0, 44]\n",
    "])\n",
    "\n",
    "BERT_unke_text_only_Llama_2_13b_chat_hf = np.array([\n",
    "    [59,  1, 15,  0,  8,  0],\n",
    "    [ 3, 62,  0,  0,  2,  0],\n",
    "    [21,  0, 60,  0,  9,  3],\n",
    "    [ 2,  0,  3, 26,  7,  6],\n",
    "    [ 6,  0,  3,  3, 81,  0],\n",
    "    [ 2,  0,  2,  1,  2, 47]\n",
    "])\n",
    "\n",
    "BERT_unke_text_only_Meta_Llama_3_1_8B_Instruct = np.array([\n",
    "    [51,  2, 20,  3,  5,  2],\n",
    "    [ 1, 66,  0,  0,  0,  0],\n",
    "    [ 6,  1, 74,  3,  9,  0],\n",
    "    [ 0,  0,  1, 36,  5,  2],\n",
    "    [11,  0,  2,  7, 73,  0],\n",
    "    [ 1,  0,  1,  8,  0, 44]\n",
    "])\n",
    "\n",
    "BERT_LSTM_ft_Llama_2_13b_chat_hf = np.array([\n",
    "    [57,  1, 18,  2,  1,  4],\n",
    "    [ 2, 64,  0,  0,  0,  1],\n",
    "    [ 9,  0, 71,  4,  6,  3],\n",
    "    [ 2,  0,  2, 34,  3,  3],\n",
    "    [ 4,  0,  5,  6, 77,  1],\n",
    "    [ 0,  0,  1,  2,  0, 51]\n",
    "])\n",
    "\n",
    "BERT_LSTM_ft_Meta_Llama_3_1_8B_Instruct = np.array([\n",
    "    [74,  1,  5,  0,  2,  1],\n",
    "    [ 1, 66,  0,  0,  0,  0],\n",
    "    [ 3,  0, 78,  1,  8,  3],\n",
    "    [ 1,  0,  1, 31,  8,  3],\n",
    "    [ 8,  0,  6,  5, 73,  1],\n",
    "    [ 0,  0,  1,  1,  0, 52]\n",
    "])\n",
    "\n",
    "BERT_LSTM_grace_Llama_2_13b_chat_hf = np.array([\n",
    "    [45,  4, 20,  4,  8,  2],\n",
    "    [ 0, 67,  0,  0,  0,  0],\n",
    "    [ 3,  0, 73,  6, 11,  0],\n",
    "    [ 0,  0,  1, 37,  4,  2],\n",
    "    [ 2,  0,  2,  9, 80,  0],\n",
    "    [ 0,  0,  1,  7,  0, 46]\n",
    "])\n",
    "\n",
    "BERT_LSTM_grace_Meta_Llama_3_1_8B_Instruct = np.array([\n",
    "    [40,  4, 27,  0, 11,  1],\n",
    "    [ 0, 67,  0,  0,  0,  0],\n",
    "    [ 7,  1, 73,  2,  9,  1],\n",
    "    [ 1,  0,  3, 29,  2,  9],\n",
    "    [ 6,  0,  6,  7, 74,  0],\n",
    "    [ 1,  0,  5,  1,  0, 47]\n",
    "])\n",
    "\n",
    "BERT_LSTM_unke_Llama_2_13b_chat_hf = np.array([\n",
    "    [56,  5, 19,  0,  3,  0],\n",
    "    [ 1, 65,  0,  0,  1,  0],\n",
    "    [11,  0, 71,  2,  8,  1],\n",
    "    [ 2,  0,  2, 30,  2,  8],\n",
    "    [ 9,  0,  6,  6, 72,  0],\n",
    "    [ 2,  0,  1,  1,  0, 50]\n",
    "])\n",
    "\n",
    "BERT_LSTM_unke_Meta_Llama_3_1_8B_Instruct = np.array([\n",
    "    [47,  3, 25,  1,  7,  0],\n",
    "    [ 2, 65,  0,  0,  0,  0],\n",
    "    [ 2,  0, 78,  2, 10,  1],\n",
    "    [ 0,  0,  2, 33,  5,  4],\n",
    "    [ 3,  0,  2,  5, 83,  0],\n",
    "    [ 1,  0,  3,  2,  0, 48]\n",
    "])\n",
    "def plot_confusion_matrix(cm, class_names, save_path, title):\n",
    "    num_classes = len(class_names)\n",
    "    c_shape = cm.shape\n",
    "    if c_shape != (num_classes, num_classes):\n",
    "        padded_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "        padded_matrix[:c_shape[0], :c_shape[1]] = cm\n",
    "        cm = padded_matrix\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "class_names = ['NE', \"FU\", \"MI\", \"OI\", \"BMI\", \"BI\"]\n",
    "\n",
    "mean_text_only = (BERT_ft_text_only_Llama_2_13b_chat_hf+BERT_ft_text_only_Meta_Llama_3_1_8B_Instruct+BERT_grace_text_only_Llama_2_13b_chat_hf+BERT_grace_text_only_Meta_Llama_3_1_8B_Instruct+BERT_unke_text_only_Llama_2_13b_chat_hf+BERT_unke_text_only_Meta_Llama_3_1_8B_Instruct)/6\n",
    "mean_sflp = (BERT_ft_SFLP_Llama_2_13b_chat_hf+BERT_ft_SFLP_Meta_Llama_3_1_8B_Instruct+BERT_grace_SFLP_Llama_2_13b_chat_hf+BERT_grace_SFLP_Meta_Llama_3_1_8B_Instruct+BERT_unke_SFLP_Llama_2_13b_chat_hf+BERT_unke_SFLP_Meta_Llama_3_1_8B_Instruct)/6\n",
    "mean_lstm = (BERT_LSTM_ft_Llama_2_13b_chat_hf+BERT_LSTM_ft_Meta_Llama_3_1_8B_Instruct+BERT_LSTM_grace_Llama_2_13b_chat_hf+BERT_LSTM_grace_Meta_Llama_3_1_8B_Instruct+BERT_LSTM_unke_Llama_2_13b_chat_hf+BERT_LSTM_unke_Meta_Llama_3_1_8B_Instruct)/6\n",
    "plot_confusion_matrix(mean_text_only, class_names, \"./figs/cm_mean_text_only.pdf\", \"Mean: BERT-text only\")\n",
    "plot_confusion_matrix(mean_sflp, class_names, \"./figs/cm_mean_sflp.pdf\", \"Mean: BERT+SFLP\")\n",
    "plot_confusion_matrix(mean_lstm, class_names, \"./figs/cm_mean_lstm.pdf\", \"Mean: BERT+LSTM\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "editdirection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
